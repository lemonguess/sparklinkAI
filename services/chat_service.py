"""èŠå¤©æœåŠ¡"""
import logging
from typing import List, Dict, Any, Optional, AsyncGenerator
import json
import time
import uuid
from openai import OpenAI
from sqlalchemy.orm import Session
from core.config import settings
from core.database import get_redis, get_db
from core.shared_state import active_streams
from models.database import ChatMessage as DBChatMessage
from services.knowledge_service import KnowledgeService
from services.search_service import SearchService
from models.enums import SearchStrategy
logger = logging.getLogger(__name__)





class ChatService:
    """èŠå¤©æœåŠ¡ç±» - é›†æˆæ™ºèƒ½æœç´¢åŠŸèƒ½"""
    
    def __init__(self, db: Optional[Session] = None):
        self.client = OpenAI(
            api_key=settings.SILICONFLOW_API_KEY,
            base_url=settings.SILICONFLOW_BASE_URL
        )
        self.redis_client = get_redis()
        self.db = db  # æ•°æ®åº“ä¼šè¯
        
        # é›†æˆæœç´¢æœåŠ¡
        self.knowledge_service = KnowledgeService()
        self.search_service = SearchService()
    
    async def intelligent_search(
        self,
        query: str,
        strategy: SearchStrategy = SearchStrategy.AUTO,
        max_results: int = 5,
        use_knowledge_base: bool = True,
        use_web_search: bool = True
    ) -> Dict[str, Any]:
        """æ™ºèƒ½æœç´¢ - æ•´åˆçŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢"""
        logger.info(f"ğŸš€ å¼€å§‹æ™ºèƒ½æœç´¢: {query}")
        
        knowledge_results = []
        web_results = []
        decision_reasoning = ""
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šçŸ¥è¯†åº“æœç´¢
            if use_knowledge_base:
                logger.info("ğŸ” æ‰§è¡ŒçŸ¥è¯†åº“æœç´¢")
                knowledge_results = await self.knowledge_service.search(
                    query=query,
                    top_k=10
                )
            
            # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½å†³ç­–æ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢
            need_web_search = False
            quality_score = 0.0
            
            if knowledge_results:
                # è®¡ç®—çŸ¥è¯†åº“ç»“æœè´¨é‡
                scores = [r.get('score', 0) for r in knowledge_results]
                quality_score = sum(scores) / len(scores) if scores else 0.0
                max_score = max(scores) if scores else 0.0
                
                # æ™ºèƒ½åˆ¤æ–­é€»è¾‘
                if strategy == SearchStrategy.AUTO:
                    need_web_search = (
                        len(knowledge_results) < 3 or  # ç»“æœæ•°é‡ä¸è¶³
                        max_score < 0.8 or  # æœ€é«˜ç›¸ä¼¼åº¦ä¸å¤Ÿ
                        quality_score < 0.7  # å¹³å‡è´¨é‡ä¸å¤Ÿ
                    )
                    decision_reasoning = f"çŸ¥è¯†åº“è´¨é‡è¯„åˆ†: {quality_score:.2f}, æœ€é«˜åˆ†: {max_score:.2f}, ç»“æœæ•°: {len(knowledge_results)}"
                elif strategy == SearchStrategy.HYBRID:
                    need_web_search = True
                    decision_reasoning = "æ··åˆç­–ç•¥ï¼šåŒæ—¶ä½¿ç”¨çŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢"
                elif strategy == SearchStrategy.WEB_FIRST:
                    need_web_search = True
                    decision_reasoning = "ç½‘ç»œä¼˜å…ˆç­–ç•¥"
                else:  # KNOWLEDGE_FIRST
                    need_web_search = quality_score < 0.6  # åªæœ‰è´¨é‡å¾ˆä½æ—¶æ‰ç½‘ç»œæœç´¢
                    decision_reasoning = f"çŸ¥è¯†åº“ä¼˜å…ˆç­–ç•¥ï¼Œè´¨é‡è¯„åˆ†: {quality_score:.2f}"
            else:
                need_web_search = use_web_search
                decision_reasoning = "çŸ¥è¯†åº“æ— ç»“æœï¼Œå¯ç”¨ç½‘ç»œæœç´¢"
            
            # ç¬¬ä¸‰æ­¥ï¼šæ¡ä»¶æ€§ç½‘ç»œæœç´¢
            if need_web_search and use_web_search:
                logger.info("ğŸŒ æ‰§è¡Œç½‘ç»œæœç´¢")
                web_results = await self.search_service.web_search(
                    query=query,
                    max_results=max_results
                )
            logger.info(f"âœ… æ™ºèƒ½æœç´¢å®Œæˆ: çŸ¥è¯†åº“{len(knowledge_results)}æ¡, ç½‘ç»œ{len(web_results)}æ¡")
            
            return {
                'knowledge_results': knowledge_results,
                'web_results': web_results,
                'decision_reasoning': decision_reasoning
            }
        except Exception as e:
            logger.error(f"æ™ºèƒ½æœç´¢å¤±è´¥: {e}", exc_info=True)
            return {
                'knowledge_results': [],
                'web_results': [],
                'decision_reasoning': f"æ™ºèƒ½æœç´¢å¤±è´¥: {e}"
            }
    
    async def generate_response(
        self,
        message: str,
        knowledge_sources: List[Dict[str, Any]] = None,
        web_search_results: List[Dict[str, Any]] = None,
        session_id: Optional[str] = None,
        stream: bool = False,
        use_intelligent_search: bool = False,
        search_strategy: SearchStrategy = SearchStrategy.AUTO
    ) -> str:
        """ç”ŸæˆèŠå¤©å›å¤"""
        try:
            # å¦‚æœå¯ç”¨æ™ºèƒ½æœç´¢ï¼Œåˆ™è‡ªåŠ¨è·å–æœç´¢ç»“æœ
            if use_intelligent_search:
                search_result = await self.intelligent_search(
                    query=message,
                    strategy=search_strategy,
                    max_results=5
                )
                
                if search_result.get('success', False):
                    knowledge_sources = search_result.get('knowledge_results', [])
                    web_search_results = search_result.get('web_results', [])
                    logger.info(f"æ™ºèƒ½æœç´¢è·å¾—: çŸ¥è¯†åº“{len(knowledge_sources)}æ¡, ç½‘ç»œ{len(web_search_results)}æ¡")
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(
                knowledge_sources=knowledge_sources,
                web_search_results=web_search_results
            )
            
            # è·å–å†å²å¯¹è¯
            conversation_history = await self._get_conversation_history(session_id)
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            # æ·»åŠ å†å²å¯¹è¯ï¼ˆæœ€è¿‘10è½®ï¼‰
            if conversation_history:
                messages.extend(conversation_history[-20:])  # æœ€è¿‘20æ¡æ¶ˆæ¯ï¼ˆ10è½®å¯¹è¯ï¼‰
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": message})
            
            # è°ƒç”¨LLMç”Ÿæˆå›å¤
            if stream:
                return await self._generate_stream_response(messages)
            else:
                return await self._generate_single_response(messages)
                
        except Exception as e:
            logger.error(f"ç”ŸæˆèŠå¤©å›å¤å¤±è´¥: {e}", exc_info=True)
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    async def generate_stream_response(
        self,
        message: str,
        knowledge_sources: List[Dict[str, Any]] = None,
        web_search_results: List[Dict[str, Any]] = None,
        session_id: Optional[str] = None,
        request_id: Optional[str] = None,  # æ·»åŠ  request_id
        use_intelligent_search: bool = False,
        search_strategy: SearchStrategy = SearchStrategy.AUTO
    ) -> AsyncGenerator[str, None]:
        """ç”Ÿæˆæµå¼èŠå¤©å›å¤"""
        try:
            # # å¦‚æœå¯ç”¨æ™ºèƒ½æœç´¢ï¼Œåˆ™è‡ªåŠ¨è·å–æœç´¢ç»“æœ
            if use_intelligent_search:
                search_result = await self.intelligent_search(
                    query=message,
                    strategy=search_strategy,
                    max_results=10
                )
                
                if search_result.get('success', False):
                    knowledge_sources = search_result.get('knowledge_results', [])
                    web_search_results = search_result.get('web_results', [])
                    logger.info(f"æ™ºèƒ½æœç´¢è·å¾—: çŸ¥è¯†åº“{len(knowledge_sources)}æ¡, ç½‘ç»œ{len(web_search_results)}æ¡")
                      
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(
                knowledge_sources=knowledge_sources,
                web_search_results=web_search_results
            )
            
            # è·å–å†å²å¯¹è¯
            conversation_history = await self._get_conversation_history(session_id)
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            if conversation_history:
                messages.extend(conversation_history[-20:])
            
            messages.append({"role": "user", "content": message})
            
            # æµå¼ç”Ÿæˆ
            try:
                response = self.client.chat.completions.create(
                    model=settings.chat_model,
                    messages=messages,
                    max_tokens=settings.max_tokens,
                    temperature=settings.temperature,
                    stream=True
                )
                
                for chunk in response:
                    # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                    if request_id and request_id in active_streams:
                        if active_streams[request_id].get('cancelled', False):
                            logger.info(f"ğŸ›‘ æµå¼å“åº”è¢«ç”¨æˆ·å–æ¶ˆ: {request_id}")
                            break
                    
                    if not chunk.choices:
                        continue
                    
                    if chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        logger.info(f"ğŸ“¤ æµå¼è¾“å‡º: '{content}' (request_id: {request_id})")
                        yield content
                        
                    if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                        reasoning = chunk.choices[0].delta.reasoning_content
                        logger.info(f"ğŸ§  æ¨ç†å†…å®¹: '{reasoning}' (request_id: {request_id})")
                        yield reasoning
                        
            except Exception as e:
                logger.error(f"æµå¼ç”Ÿæˆå¤±è´¥: {e}")
                yield "æŠ±æ­‰ï¼Œç”Ÿæˆå›å¤æ—¶å‡ºç°é”™è¯¯ã€‚"
                
        except Exception as e:
            logger.error(f"æµå¼èŠå¤©æœåŠ¡å¤±è´¥: {e}", exc_info=True)
            yield "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
    
    async def _generate_single_response(self, messages: List[Dict[str, str]]) -> str:
        """ç”Ÿæˆå•æ¬¡å›å¤"""
        try:
            response = self.client.chat.completions.create(
                model=settings.chat_model,
                messages=messages,
                max_tokens=settings.max_tokens,
                temperature=settings.temperature
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"è°ƒç”¨LLMå¤±è´¥: {e}")
            raise
    

    
    def _build_system_prompt(
        self,
        knowledge_sources: List[Dict[str, Any]] = None,
        web_search_results: List[Dict[str, Any]] = None
    ) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        base_prompt = """ä½ æ˜¯SparkLink AIï¼Œä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚

å›ç­”è¦æ±‚ï¼š
1. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰æ¡ç†
2. å¦‚æœæœ‰ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹æˆ–æœç´¢ç»“æœï¼Œè¯·ä¼˜å…ˆå‚è€ƒè¿™äº›ä¿¡æ¯
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜
4. ä¿æŒå‹å¥½ã€ä¸“ä¸šçš„è¯­è°ƒ
"""
        
        # æ·»åŠ çŸ¥è¯†åº“ä¿¡æ¯
        if knowledge_sources:
            base_prompt += "\n\n**ç›¸å…³çŸ¥è¯†åº“å†…å®¹ï¼š**\n"
            for i, source in enumerate(knowledge_sources[:5], 1):  # æœ€å¤š5ä¸ªæ¥æº
                content = source.get('content', '').strip()
                score = source.get('score', 0)
                base_prompt += f"{i}. [ç›¸ä¼¼åº¦: {score:.2f}] {content}\n"
        
        # æ·»åŠ æœç´¢ç»“æœ
        if web_search_results:
            base_prompt += "\n\n**ç›¸å…³æœç´¢ç»“æœï¼š**\n"
            for i, result in enumerate(web_search_results[:3], 1):  # æœ€å¤š3ä¸ªæœç´¢ç»“æœ
                title = result.get('title', '').strip()
                content = result.get('content', '').strip()
                url = result.get('url', '')
                base_prompt += f"{i}. **{title}**\n{content}\næ¥æº: {url}\n\n"
        
        return base_prompt
    
    async def _get_conversation_history(self, session_id: Optional[str]) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        if not session_id:
            return []
        
        try:
            cache_key = f"session:{session_id}:messages"
            
            # ä»Redisç¼“å­˜è·å–
            cached_history = self.redis_client.get(cache_key)
            if cached_history:
                logger.info(f"ä»Redisç¼“å­˜è·å–ä¼šè¯ {session_id} çš„èŠå¤©å†å²")
                cached_data = json.loads(cached_history)
                # è½¬æ¢ä¸ºç®€åŒ–æ ¼å¼ç”¨äºå¯¹è¯ä¸Šä¸‹æ–‡
                return [{"role": msg["role"], "content": msg["content"]} for msg in cached_data]
            
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä»MySQLæ•°æ®åº“è·å–
            if self.db:
                logger.info(f"Redisç¼“å­˜æœªå‘½ä¸­ï¼Œä»MySQLæŸ¥è¯¢ä¼šè¯ {session_id} çš„èŠå¤©å†å²")
                messages = self.db.query(DBChatMessage).filter(
                    DBChatMessage.session_id == session_id
                ).order_by(DBChatMessage.created_at.asc()).limit(50).all()
                
                # è½¬æ¢ä¸ºå®Œæ•´æ ¼å¼
                full_history = []
                simple_history = []
                for msg in messages:
                    msg_data = {
                        "role": msg.role,
                        "content": msg.content,
                        "created_at": msg.created_at.timestamp() if msg.created_at else time.time()
                    }
                    if msg.knowledge_sources:
                        msg_data["knowledge_sources"] = json.loads(msg.knowledge_sources)
                    if msg.web_search_results:
                        msg_data["web_search_results"] = json.loads(msg.web_search_results)
                    
                    full_history.append(msg_data)
                    simple_history.append({"role": msg.role, "content": msg.content})
                
                # å°†å®Œæ•´æ ¼å¼ç¼“å­˜åˆ°Redisï¼ˆ24å°æ—¶è¿‡æœŸï¼‰
                if full_history:
                    self.redis_client.setex(
                        cache_key,
                        86400,  # 24å°æ—¶
                        json.dumps(full_history, ensure_ascii=False)
                    )
                    logger.info(f"å·²å°†ä¼šè¯ {session_id} çš„ {len(full_history)} æ¡æ¶ˆæ¯ç¼“å­˜åˆ°Redis")
                
                return simple_history
            else:
                logger.warning("æ•°æ®åº“ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æŸ¥è¯¢MySQL")
                return []
            
        except Exception as e:
            logger.warning(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return []
    
    async def save_conversation_history(
        self,
        session_id: str,
        user_message: str,
        assistant_message: str,
        knowledge_sources: Optional[List[Dict[str, Any]]] = None,
        web_search_results: Optional[List[Dict[str, Any]]] = None,
        user_request_id: Optional[str] = None,
        assistant_request_id: Optional[str] = None
    ):
        """ä¿å­˜å¯¹è¯å†å²åˆ°MySQLå’ŒRedisç¼“å­˜"""
        try:
            # ç”Ÿæˆè¯·æ±‚ID
            user_req_id = user_request_id or uuid.uuid4().hex
            assistant_req_id = assistant_request_id or uuid.uuid4().hex
            
            # 1. ä¿å­˜åˆ°MySQLæ•°æ®åº“
            if self.db:
                # è·å–å½“å‰ä¼šè¯çš„æœ€å¤§åºå·
                max_sequence = self.db.query(DBChatMessage.sequence_number).filter(
                    DBChatMessage.session_id == session_id
                ).order_by(DBChatMessage.sequence_number.desc()).first()
                
                next_sequence = (max_sequence[0] + 1) if max_sequence and max_sequence[0] is not None else 1
                
                # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                user_msg = DBChatMessage(
                    session_id=session_id,
                    request_id=user_req_id,
                    role="user",
                    content=user_message,
                    sequence_number=next_sequence
                )
                self.db.add(user_msg)
                
                # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
                assistant_msg = DBChatMessage(
                    session_id=session_id,
                    request_id=assistant_req_id,
                    role="assistant",
                    content=assistant_message,
                    sequence_number=next_sequence + 1,
                    knowledge_sources=json.dumps(knowledge_sources, ensure_ascii=False) if knowledge_sources else None,
                    web_search_results=json.dumps(web_search_results, ensure_ascii=False) if web_search_results else None
                )
                self.db.add(assistant_msg)
                self.db.commit()
                logger.info(f"å·²ä¿å­˜ä¼šè¯ {session_id} çš„å¯¹è¯åˆ°MySQLæ•°æ®åº“")
            else:
                logger.warning("æ•°æ®åº“ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜åˆ°MySQL")
            
            # 2. æ›´æ–°Redisç¼“å­˜
            cache_key = f"session:{session_id}:messages"
            
            # è·å–ç°æœ‰å†å²
            existing_history = await self._get_conversation_history(session_id)
            
            # æ·»åŠ æ–°çš„å¯¹è¯
            existing_history.extend([
                {
                    "role": "user", 
                    "content": user_message,
                    "created_at": time.time()
                },
                {
                    "role": "assistant", 
                    "content": assistant_message,
                    "created_at": time.time(),
                    "knowledge_sources": knowledge_sources,
                    "web_search_results": web_search_results
                }
            ])
            
            # ä¿æŒæœ€è¿‘50æ¡æ¶ˆæ¯
            if len(existing_history) > 50:
                existing_history = existing_history[-50:]
            
            # ä¿å­˜åˆ°Redisï¼Œè¿‡æœŸæ—¶é—´24å°æ—¶
            self.redis_client.setex(
                cache_key,
                86400,  # 24å°æ—¶
                json.dumps(existing_history, ensure_ascii=False)
            )
            logger.info(f"å·²æ›´æ–°ä¼šè¯ {session_id} çš„Redisç¼“å­˜ï¼Œå…± {len(existing_history)} æ¡æ¶ˆæ¯")
            
        except Exception as e:
            logger.warning(f"ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {e}")
            if self.db:
                self.db.rollback()
    
    async def handle_stream_interruption(
        self,
        request_id: str,
        session_id: str,
        user_message: str,
        partial_response: str,
        knowledge_sources: Optional[List[Dict[str, Any]]] = None,
        web_search_results: Optional[List[Dict[str, Any]]] = None
    ):
        """å¤„ç†æµå¼å“åº”ä¸­æ–­ï¼Œä¿å­˜å·²ç”Ÿæˆçš„å†…å®¹"""
        try:
            if partial_response.strip():  # åªæœ‰å½“æœ‰å®é™…å†…å®¹æ—¶æ‰ä¿å­˜
                # åœ¨æ¶ˆæ¯æœ«å°¾æ·»åŠ ä¸­æ–­æ ‡è®°
                final_message = partial_response + "\n\n[æ­¤æ¶ˆæ¯å·²è¢«ç”¨æˆ·ä¸­æ–­]"
                
                await self.save_conversation_history(
                    session_id=session_id,
                    user_message=user_message,
                    assistant_message=final_message,
                    knowledge_sources=knowledge_sources,
                    web_search_results=web_search_results
                )
                logger.info(f"ğŸ’¾ å·²ä¿å­˜è¢«ä¸­æ–­çš„å¯¹è¯è®°å½•ï¼Œrequest_id: {request_id}, å†…å®¹é•¿åº¦: {len(final_message)}")
            else:
                logger.info(f"âš ï¸ ä¸­æ–­æ—¶æ— å†…å®¹å¯ä¿å­˜ï¼Œrequest_id: {request_id}")
        except Exception as e:
            logger.error(f"å¤„ç†æµå¼ä¸­æ–­æ—¶ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {e}")
    
    async def stop_stream_generation(self, request_id: str) -> bool:
        """åœæ­¢æµå¼ç”Ÿæˆå¹¶æ ‡è®°ä¸ºå·²å–æ¶ˆ"""
        try:
            if request_id not in active_streams:
                logger.warning(f"å°è¯•åœæ­¢ä¸å­˜åœ¨çš„æµå¼è¯·æ±‚: {request_id}")
                return False
            
            active_streams[request_id]["cancelled"] = True
            logger.info(f"ğŸ›‘ å·²æ ‡è®°æµå¼è¯·æ±‚ä¸ºå–æ¶ˆçŠ¶æ€: {request_id}")
            return True
        except Exception as e:
            logger.error(f"åœæ­¢æµå¼ç”Ÿæˆå¤±è´¥: {e}")
            return False
    
    async def intelligent_chat(
        self,
        message: str,
        session_id: Optional[str] = None,
        strategy: SearchStrategy = SearchStrategy.AUTO,
        stream: bool = False
    ) -> str:
        """æ™ºèƒ½èŠå¤© - è‡ªåŠ¨æœç´¢å¹¶ç”Ÿæˆå›å¤çš„ä¾¿æ·æ¥å£"""
        if stream:
            return self.generate_stream_response(
                message=message,
                session_id=session_id,
                use_intelligent_search=True,
                search_strategy=strategy
            )
        else:
            return await self.generate_response(
                message=message,
                session_id=session_id,
                use_intelligent_search=True,
                search_strategy=strategy
            )
    
    async def clear_conversation_history(self, session_id: str):
        """æ¸…é™¤å¯¹è¯å†å²"""
        try:
            cache_key = f"chat_history:{session_id}"
            self.redis_client.delete(cache_key)
        except Exception as e:
            logger.warning(f"æ¸…é™¤å¯¹è¯å†å²å¤±è´¥: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "chat_model": settings.chat_model,
            "max_tokens": settings.max_tokens,
            "temperature": settings.temperature,
            "base_url": settings.SILICONFLOW_BASE_URL
        }
    
    async def generate_session_title_from_input(self, user_message: str) -> str:
        """æ ¹æ®ç”¨æˆ·è¾“å…¥å¿«é€Ÿç”Ÿæˆä¼šè¯æ ‡é¢˜"""
        try:
            # æ„å»ºç”Ÿæˆæ ‡é¢˜çš„æç¤º
            prompt = f"""è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æˆ–éœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´ã€å‡†ç¡®çš„ä¼šè¯æ ‡é¢˜ï¼ˆä¸è¶…è¿‡15ä¸ªå­—ç¬¦ï¼‰ï¼š

ç”¨æˆ·è¾“å…¥ï¼š{user_message[:100]}

è¦æ±‚ï¼š
1. æ ‡é¢˜è¦ç®€æ´æ˜äº†ï¼Œèƒ½æ¦‚æ‹¬ç”¨æˆ·çš„é—®é¢˜æˆ–éœ€æ±‚
2. ä¸è¶…è¿‡15ä¸ªå­—ç¬¦
3. ä¸è¦åŒ…å«æ ‡ç‚¹ç¬¦å·
4. ç›´æ¥è¿”å›æ ‡é¢˜ï¼Œä¸è¦å…¶ä»–å†…å®¹"""
            
            response = self.client.chat.completions.create(
                model=settings.chat_model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=30,
                temperature=0.5
            )
            
            title = response.choices[0].message.content.strip()
            # ç¡®ä¿æ ‡é¢˜é•¿åº¦ä¸è¶…è¿‡15ä¸ªå­—ç¬¦
            if len(title) > 15:
                title = title[:15]
            
            return title
            
        except Exception as e:
            logger.error(f"å¿«é€Ÿç”Ÿæˆä¼šè¯æ ‡é¢˜å¤±è´¥: {e}")
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸºäºç”¨æˆ·æ¶ˆæ¯çš„ç®€å•æ ‡é¢˜
            return user_message[:12] + "..." if len(user_message) > 12 else user_message
    
    async def generate_session_title(self, user_message: str, assistant_message: str) -> str:
        """æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆä¼šè¯æ ‡é¢˜"""
        try:
            # æ„å»ºç”Ÿæˆæ ‡é¢˜çš„æç¤º
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´ã€å‡†ç¡®çš„ä¼šè¯æ ‡é¢˜ï¼ˆä¸è¶…è¿‡20ä¸ªå­—ç¬¦ï¼‰ï¼š

ç”¨æˆ·ï¼š{user_message[:200]}
åŠ©æ‰‹ï¼š{assistant_message[:200]}

è¦æ±‚ï¼š
1. æ ‡é¢˜è¦ç®€æ´æ˜äº†ï¼Œèƒ½æ¦‚æ‹¬å¯¹è¯ä¸»é¢˜
2. ä¸è¶…è¿‡20ä¸ªå­—ç¬¦
3. ä¸è¦åŒ…å«æ ‡ç‚¹ç¬¦å·
4. ç›´æ¥è¿”å›æ ‡é¢˜ï¼Œä¸è¦å…¶ä»–å†…å®¹"""
            
            response = self.client.chat.completions.create(
                model=settings.chat_model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=50,
                temperature=0.7
            )
            
            title = response.choices[0].message.content.strip()
            # ç¡®ä¿æ ‡é¢˜é•¿åº¦ä¸è¶…è¿‡20ä¸ªå­—ç¬¦
            if len(title) > 20:
                title = title[:20]
            
            return title
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆä¼šè¯æ ‡é¢˜å¤±è´¥: {e}")
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œè¿”å›åŸºäºç”¨æˆ·æ¶ˆæ¯çš„ç®€å•æ ‡é¢˜
            return user_message[:15] + "..." if len(user_message) > 15 else user_message
    
    async def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        try:
            response = self.client.chat.completions.create(
                model=settings.chat_model,
                messages=[
                    {"role": "user", "content": "Hello"}
                ],
                max_tokens=10
            )
            return True
        except Exception as e:
            logger.error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False