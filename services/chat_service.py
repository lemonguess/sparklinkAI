"""èŠå¤©æœåŠ¡"""
import logging
from typing import List, Dict, Any, Optional, AsyncGenerator
import json
import time
import uuid
from enum import Enum

import openai
from openai import OpenAI
from sqlalchemy.orm import Session

from core.config import settings
from core.database import get_redis, get_db
from models.database import ChatMessage as DBChatMessage
from services.knowledge_service import KnowledgeService
from services.search_service import SearchService

logger = logging.getLogger(__name__)


class SearchStrategy(Enum):
    """æœç´¢ç­–ç•¥æšä¸¾"""
    KNOWLEDGE_FIRST = "knowledge_first"
    WEB_FIRST = "web_first"
    HYBRID = "hybrid"
    AUTO = "auto"


class ChatService:
    """èŠå¤©æœåŠ¡ç±» - é›†æˆæ™ºèƒ½æœç´¢åŠŸèƒ½"""
    
    def __init__(self, db: Optional[Session] = None):
        self.client = OpenAI(
            api_key=settings.SILICONFLOW_API_KEY,
            base_url=settings.SILICONFLOW_BASE_URL
        )
        self.redis_client = get_redis()
        self.db = db  # æ•°æ®åº“ä¼šè¯
        
        # é›†æˆæœç´¢æœåŠ¡
        self.knowledge_service = KnowledgeService()
        self.search_service = SearchService()
    
    async def intelligent_search(
        self,
        query: str,
        strategy: SearchStrategy = SearchStrategy.AUTO,
        max_results: int = 5,
        use_knowledge_base: bool = True,
        use_web_search: bool = True
    ) -> Dict[str, Any]:
        """æ™ºèƒ½æœç´¢ - æ•´åˆçŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢"""
        logger.info(f"ğŸš€ å¼€å§‹æ™ºèƒ½æœç´¢: {query}")
        
        knowledge_results = []
        web_results = []
        decision_reasoning = ""
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šçŸ¥è¯†åº“æœç´¢
            if use_knowledge_base:
                logger.info("ğŸ” æ‰§è¡ŒçŸ¥è¯†åº“æœç´¢")
                knowledge_results = await self.knowledge_service.search(
                    query=query,
                    top_k=10
                )
            
            # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½å†³ç­–æ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢
            need_web_search = False
            quality_score = 0.0
            
            if knowledge_results:
                # è®¡ç®—çŸ¥è¯†åº“ç»“æœè´¨é‡
                scores = [r.get('score', 0) for r in knowledge_results]
                quality_score = sum(scores) / len(scores) if scores else 0.0
                max_score = max(scores) if scores else 0.0
                
                # æ™ºèƒ½åˆ¤æ–­é€»è¾‘
                if strategy == SearchStrategy.AUTO:
                    need_web_search = (
                        len(knowledge_results) < 3 or  # ç»“æœæ•°é‡ä¸è¶³
                        max_score < 0.8 or  # æœ€é«˜ç›¸ä¼¼åº¦ä¸å¤Ÿ
                        quality_score < 0.7  # å¹³å‡è´¨é‡ä¸å¤Ÿ
                    )
                    decision_reasoning = f"çŸ¥è¯†åº“è´¨é‡è¯„åˆ†: {quality_score:.2f}, æœ€é«˜åˆ†: {max_score:.2f}, ç»“æœæ•°: {len(knowledge_results)}"
                elif strategy == SearchStrategy.HYBRID:
                    need_web_search = True
                    decision_reasoning = "æ··åˆç­–ç•¥ï¼šåŒæ—¶ä½¿ç”¨çŸ¥è¯†åº“å’Œç½‘ç»œæœç´¢"
                elif strategy == SearchStrategy.WEB_FIRST:
                    need_web_search = True
                    decision_reasoning = "ç½‘ç»œä¼˜å…ˆç­–ç•¥"
                else:  # KNOWLEDGE_FIRST
                    need_web_search = quality_score < 0.6  # åªæœ‰è´¨é‡å¾ˆä½æ—¶æ‰ç½‘ç»œæœç´¢
                    decision_reasoning = f"çŸ¥è¯†åº“ä¼˜å…ˆç­–ç•¥ï¼Œè´¨é‡è¯„åˆ†: {quality_score:.2f}"
            else:
                need_web_search = use_web_search
                decision_reasoning = "çŸ¥è¯†åº“æ— ç»“æœï¼Œå¯ç”¨ç½‘ç»œæœç´¢"
            
            # ç¬¬ä¸‰æ­¥ï¼šæ¡ä»¶æ€§ç½‘ç»œæœç´¢
            if need_web_search and use_web_search:
                logger.info("ğŸŒ æ‰§è¡Œç½‘ç»œæœç´¢")
                web_results = await self.search_service.web_search(
                    query=query,
                    max_results=max_results
                )
            
            # ç¬¬å››æ­¥ï¼šç»“æœåˆå¹¶å’Œæ’åº
            logger.info("ğŸ”— åˆå¹¶æœç´¢ç»“æœ")
            final_results = self.search_service.filter_and_rank_results(
                knowledge_results=knowledge_results,
                web_results=web_results,
                max_results=max_results
            )
            
            logger.info(f"âœ… æ™ºèƒ½æœç´¢å®Œæˆ: çŸ¥è¯†åº“{len(knowledge_results)}æ¡, ç½‘ç»œ{len(web_results)}æ¡, æœ€ç»ˆ{len(final_results)}æ¡")
            
            return {
                'query': query,
                'results': final_results,
                'knowledge_results': knowledge_results,
                'web_results': web_results,
                'strategy': strategy,
                'success': True,
                'total_results_count': len(final_results),
                'decision_reasoning': decision_reasoning,
                'quality_metrics': {
                    'knowledge_quality': quality_score,
                    'knowledge_count': len(knowledge_results),
                    'web_count': len(web_results),
                    'used_web_search': need_web_search
                },
                'performance_metrics': {
                    'framework': 'Integrated ChatService',
                    'total_time': 0.01
                }
            }
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½æœç´¢å¤±è´¥: {e}", exc_info=True)
            return {
                'query': query,
                'results': [],
                'success': False,
                'error': str(e),
                'strategy': strategy
            }
    
    async def generate_response(
        self,
        message: str,
        knowledge_sources: List[Dict[str, Any]] = None,
        web_search_results: List[Dict[str, Any]] = None,
        session_id: Optional[str] = None,
        stream: bool = False,
        use_intelligent_search: bool = False,
        search_strategy: SearchStrategy = SearchStrategy.AUTO
    ) -> str:
        """ç”ŸæˆèŠå¤©å›å¤"""
        try:
            # å¦‚æœå¯ç”¨æ™ºèƒ½æœç´¢ï¼Œåˆ™è‡ªåŠ¨è·å–æœç´¢ç»“æœ
            if use_intelligent_search:
                search_result = await self.intelligent_search(
                    query=message,
                    strategy=search_strategy,
                    max_results=5
                )
                
                if search_result.get('success', False):
                    knowledge_sources = search_result.get('knowledge_results', [])
                    web_search_results = search_result.get('web_results', [])
                    logger.info(f"æ™ºèƒ½æœç´¢è·å¾—: çŸ¥è¯†åº“{len(knowledge_sources)}æ¡, ç½‘ç»œ{len(web_search_results)}æ¡")
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(
                knowledge_sources=knowledge_sources,
                web_search_results=web_search_results
            )
            
            # è·å–å†å²å¯¹è¯
            conversation_history = await self._get_conversation_history(session_id)
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            # æ·»åŠ å†å²å¯¹è¯ï¼ˆæœ€è¿‘10è½®ï¼‰
            if conversation_history:
                messages.extend(conversation_history[-20:])  # æœ€è¿‘20æ¡æ¶ˆæ¯ï¼ˆ10è½®å¯¹è¯ï¼‰
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": message})
            
            # è°ƒç”¨LLMç”Ÿæˆå›å¤
            if stream:
                return await self._generate_stream_response(messages)
            else:
                return await self._generate_single_response(messages)
                
        except Exception as e:
            logger.error(f"ç”ŸæˆèŠå¤©å›å¤å¤±è´¥: {e}", exc_info=True)
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    async def generate_stream_response(
        self,
        message: str,
        knowledge_sources: List[Dict[str, Any]] = None,
        web_search_results: List[Dict[str, Any]] = None,
        session_id: Optional[str] = None,
        use_intelligent_search: bool = False,
        search_strategy: SearchStrategy = SearchStrategy.AUTO
    ) -> AsyncGenerator[str, None]:
        """ç”Ÿæˆæµå¼èŠå¤©å›å¤"""
        try:
            # å¦‚æœå¯ç”¨æ™ºèƒ½æœç´¢ï¼Œåˆ™è‡ªåŠ¨è·å–æœç´¢ç»“æœ
            if use_intelligent_search:
                search_result = await self.intelligent_search(
                    query=message,
                    strategy=search_strategy,
                    max_results=5
                )
                
                if search_result.get('success', False):
                    knowledge_sources = search_result.get('knowledge_results', [])
                    web_search_results = search_result.get('web_results', [])
                    logger.info(f"æ™ºèƒ½æœç´¢è·å¾—: çŸ¥è¯†åº“{len(knowledge_sources)}æ¡, ç½‘ç»œ{len(web_search_results)}æ¡")
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt(
                knowledge_sources=knowledge_sources,
                web_search_results=web_search_results
            )
            
            # è·å–å†å²å¯¹è¯
            conversation_history = await self._get_conversation_history(session_id)
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            if conversation_history:
                messages.extend(conversation_history[-20:])
            
            messages.append({"role": "user", "content": message})
            
            # æµå¼ç”Ÿæˆ
            try:
                response = self.client.chat.completions.create(
                    model=settings.chat_model,
                    messages=messages,
                    max_tokens=settings.max_tokens,
                    temperature=settings.temperature,
                    stream=True
                )
                
                for chunk in response:
                    if not chunk.choices:
                        continue
                    if chunk.choices[0].delta.content:
                        yield chunk.choices[0].delta.content
                    if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                        yield chunk.choices[0].delta.reasoning_content
                        
            except Exception as e:
                logger.error(f"æµå¼ç”Ÿæˆå¤±è´¥: {e}")
                yield "æŠ±æ­‰ï¼Œç”Ÿæˆå›å¤æ—¶å‡ºç°é”™è¯¯ã€‚"
                
        except Exception as e:
            logger.error(f"æµå¼èŠå¤©æœåŠ¡å¤±è´¥: {e}", exc_info=True)
            yield "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚"
    
    async def _generate_single_response(self, messages: List[Dict[str, str]]) -> str:
        """ç”Ÿæˆå•æ¬¡å›å¤"""
        try:
            response = self.client.chat.completions.create(
                model=settings.chat_model,
                messages=messages,
                max_tokens=settings.max_tokens,
                temperature=settings.temperature
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"è°ƒç”¨LLMå¤±è´¥: {e}")
            raise
    
    async def _generate_stream_response(self, messages: List[Dict[str, str]]) -> str:
        """ç”Ÿæˆæµå¼å›å¤ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰"""
        try:
            response = self.client.chat.completions.create(
                model=settings.chat_model,
                messages=messages,
                max_tokens=settings.max_tokens,
                temperature=settings.temperature,
                stream=True
            )
            
            full_response = ""
            for chunk in response:
                if not chunk.choices:
                    continue
                if chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                if hasattr(chunk.choices[0].delta, 'reasoning_content') and chunk.choices[0].delta.reasoning_content:
                    full_response += chunk.choices[0].delta.reasoning_content
            
            return full_response.strip()
            
        except Exception as e:
            logger.error(f"æµå¼ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _build_system_prompt(
        self,
        knowledge_sources: List[Dict[str, Any]] = None,
        web_search_results: List[Dict[str, Any]] = None
    ) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        base_prompt = """ä½ æ˜¯SparkLink AIï¼Œä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ã€‚

å›ç­”è¦æ±‚ï¼š
1. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰æ¡ç†
2. å¦‚æœæœ‰ç›¸å…³çš„çŸ¥è¯†åº“å†…å®¹æˆ–æœç´¢ç»“æœï¼Œè¯·ä¼˜å…ˆå‚è€ƒè¿™äº›ä¿¡æ¯
3. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜
4. ä¿æŒå‹å¥½ã€ä¸“ä¸šçš„è¯­è°ƒ
"""
        
        # æ·»åŠ çŸ¥è¯†åº“ä¿¡æ¯
        if knowledge_sources:
            base_prompt += "\n\n**ç›¸å…³çŸ¥è¯†åº“å†…å®¹ï¼š**\n"
            for i, source in enumerate(knowledge_sources[:5], 1):  # æœ€å¤š5ä¸ªæ¥æº
                content = source.get('content', '').strip()
                score = source.get('score', 0)
                base_prompt += f"{i}. [ç›¸ä¼¼åº¦: {score:.2f}] {content}\n"
        
        # æ·»åŠ æœç´¢ç»“æœ
        if web_search_results:
            base_prompt += "\n\n**ç›¸å…³æœç´¢ç»“æœï¼š**\n"
            for i, result in enumerate(web_search_results[:3], 1):  # æœ€å¤š3ä¸ªæœç´¢ç»“æœ
                title = result.get('title', '').strip()
                content = result.get('content', '').strip()
                url = result.get('url', '')
                base_prompt += f"{i}. **{title}**\n{content}\næ¥æº: {url}\n\n"
        
        return base_prompt
    
    async def _get_conversation_history(self, session_id: Optional[str]) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        if not session_id:
            return []
        
        try:
            cache_key = f"session:{session_id}:messages"
            
            # ä»Redisç¼“å­˜è·å–
            cached_history = self.redis_client.get(cache_key)
            if cached_history:
                logger.info(f"ä»Redisç¼“å­˜è·å–ä¼šè¯ {session_id} çš„èŠå¤©å†å²")
                cached_data = json.loads(cached_history)
                # è½¬æ¢ä¸ºç®€åŒ–æ ¼å¼ç”¨äºå¯¹è¯ä¸Šä¸‹æ–‡
                return [{"role": msg["role"], "content": msg["content"]} for msg in cached_data]
            
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä»MySQLæ•°æ®åº“è·å–
            if self.db:
                logger.info(f"Redisç¼“å­˜æœªå‘½ä¸­ï¼Œä»MySQLæŸ¥è¯¢ä¼šè¯ {session_id} çš„èŠå¤©å†å²")
                messages = self.db.query(DBChatMessage).filter(
                    DBChatMessage.session_id == session_id
                ).order_by(DBChatMessage.created_at.asc()).limit(50).all()
                
                # è½¬æ¢ä¸ºå®Œæ•´æ ¼å¼
                full_history = []
                simple_history = []
                for msg in messages:
                    msg_data = {
                        "message_id": msg.message_id,
                        "role": msg.role,
                        "content": msg.content,
                        "created_at": msg.created_at.timestamp() if msg.created_at else time.time()
                    }
                    if msg.knowledge_sources:
                        msg_data["knowledge_sources"] = json.loads(msg.knowledge_sources)
                    if msg.web_search_results:
                        msg_data["web_search_results"] = json.loads(msg.web_search_results)
                    
                    full_history.append(msg_data)
                    simple_history.append({"role": msg.role, "content": msg.content})
                
                # å°†å®Œæ•´æ ¼å¼ç¼“å­˜åˆ°Redisï¼ˆ24å°æ—¶è¿‡æœŸï¼‰
                if full_history:
                    self.redis_client.setex(
                        cache_key,
                        86400,  # 24å°æ—¶
                        json.dumps(full_history, ensure_ascii=False)
                    )
                    logger.info(f"å·²å°†ä¼šè¯ {session_id} çš„ {len(full_history)} æ¡æ¶ˆæ¯ç¼“å­˜åˆ°Redis")
                
                return simple_history
            else:
                logger.warning("æ•°æ®åº“ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æŸ¥è¯¢MySQL")
                return []
            
        except Exception as e:
            logger.warning(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return []
    
    async def save_conversation_history(
        self,
        session_id: str,
        user_message: str,
        assistant_message: str,
        knowledge_sources: Optional[List[Dict[str, Any]]] = None,
        web_search_results: Optional[List[Dict[str, Any]]] = None,
        user_message_id: Optional[str] = None,
        assistant_message_id: Optional[str] = None
    ):
        """ä¿å­˜å¯¹è¯å†å²åˆ°MySQLå’ŒRedisç¼“å­˜"""
        try:
            # ç”Ÿæˆæ¶ˆæ¯ID
            user_msg_id = user_message_id or str(uuid.uuid4())
            assistant_msg_id = assistant_message_id or str(uuid.uuid4())
            
            # 1. ä¿å­˜åˆ°MySQLæ•°æ®åº“
            if self.db:
                # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                user_msg = DBChatMessage(
                    session_id=session_id,
                    message_id=user_msg_id,
                    role="user",
                    content=user_message
                )
                self.db.add(user_msg)
                
                # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
                assistant_msg = DBChatMessage(
                    session_id=session_id,
                    message_id=assistant_msg_id,
                    role="assistant",
                    content=assistant_message,
                    knowledge_sources=json.dumps(knowledge_sources, ensure_ascii=False) if knowledge_sources else None,
                    web_search_results=json.dumps(web_search_results, ensure_ascii=False) if web_search_results else None
                )
                self.db.add(assistant_msg)
                self.db.commit()
                logger.info(f"å·²ä¿å­˜ä¼šè¯ {session_id} çš„å¯¹è¯åˆ°MySQLæ•°æ®åº“")
            else:
                logger.warning("æ•°æ®åº“ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜åˆ°MySQL")
            
            # 2. æ›´æ–°Redisç¼“å­˜
            cache_key = f"session:{session_id}:messages"
            
            # è·å–ç°æœ‰å†å²
            existing_history = await self._get_conversation_history(session_id)
            
            # æ·»åŠ æ–°çš„å¯¹è¯ï¼ˆåŒ…å«message_idï¼‰
            existing_history.extend([
                {
                    "message_id": user_msg_id,
                    "role": "user", 
                    "content": user_message,
                    "created_at": time.time()
                },
                {
                    "message_id": assistant_msg_id,
                    "role": "assistant", 
                    "content": assistant_message,
                    "created_at": time.time(),
                    "knowledge_sources": knowledge_sources,
                    "web_search_results": web_search_results
                }
            ])
            
            # ä¿æŒæœ€è¿‘50æ¡æ¶ˆæ¯
            if len(existing_history) > 50:
                existing_history = existing_history[-50:]
            
            # ä¿å­˜åˆ°Redisï¼Œè¿‡æœŸæ—¶é—´24å°æ—¶
            self.redis_client.setex(
                cache_key,
                86400,  # 24å°æ—¶
                json.dumps(existing_history, ensure_ascii=False)
            )
            logger.info(f"å·²æ›´æ–°ä¼šè¯ {session_id} çš„Redisç¼“å­˜ï¼Œå…± {len(existing_history)} æ¡æ¶ˆæ¯")
            
        except Exception as e:
            logger.warning(f"ä¿å­˜å¯¹è¯å†å²å¤±è´¥: {e}")
            if self.db:
                self.db.rollback()
    
    async def intelligent_chat(
        self,
        message: str,
        session_id: Optional[str] = None,
        strategy: SearchStrategy = SearchStrategy.AUTO,
        stream: bool = False
    ) -> str:
        """æ™ºèƒ½èŠå¤© - è‡ªåŠ¨æœç´¢å¹¶ç”Ÿæˆå›å¤çš„ä¾¿æ·æ¥å£"""
        if stream:
            return self.generate_stream_response(
                message=message,
                session_id=session_id,
                use_intelligent_search=True,
                search_strategy=strategy
            )
        else:
            return await self.generate_response(
                message=message,
                session_id=session_id,
                use_intelligent_search=True,
                search_strategy=strategy
            )
    
    async def clear_conversation_history(self, session_id: str):
        """æ¸…é™¤å¯¹è¯å†å²"""
        try:
            cache_key = f"chat_history:{session_id}"
            self.redis_client.delete(cache_key)
        except Exception as e:
            logger.warning(f"æ¸…é™¤å¯¹è¯å†å²å¤±è´¥: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "chat_model": settings.chat_model,
            "max_tokens": settings.max_tokens,
            "temperature": settings.temperature,
            "base_url": settings.SILICONFLOW_BASE_URL
        }
    
    async def test_connection(self) -> bool:
        """æµ‹è¯•LLMè¿æ¥"""
        try:
            response = self.client.chat.completions.create(
                model=settings.chat_model,
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10
            )
            return True
        except Exception as e:
            logger.error(f"LLMè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False